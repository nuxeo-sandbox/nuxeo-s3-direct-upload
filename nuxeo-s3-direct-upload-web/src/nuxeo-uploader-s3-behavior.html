<!--
@license
(C) Copyright Nuxeo Corp. (http://nuxeo.com/)

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<script type="text/javascript" src="../bower_components/aws-sdk-js/dist/aws-sdk.js"></script>
<script type="text/javascript" src="../bower_components/js-spark-md5/spark-md5.js"></script>

<script>
  var Nuxeo = Nuxeo || {};

  /**
   * @polymerBehavior Nuxeo.UploaderBehavior
   */
  Nuxeo.S3UploaderBehavior = {

    properties: {
      /**
       * Accepted file extensions or mime types (comma separated values).
       */
      accept: String,

      /**
       * This flag determines whether the file should be immediately uploaded or not.
       */
      immediate: {
        type: Boolean,
        value: true
      },

      /**
       * Current batch id.
       */
      batchId: String,

      /**
       * List of files in the current batch.
       */
      files: {
        type: Array,
        value: []
      },

      /**
       * Flag that indicates if an upload is in progress.
       */
      uploading: {
        type: Boolean,
        value: false
      },

      /**
       * Allow multiple files to be added to the same batch.
       */
      batchAppend: {
        type: Boolean,
        value: false
      }
    },

    setupDropZone: function(el) {
      this._dropZone = el;
      this._dropZone.addEventListener('dragover', this._dragover.bind(this));
      this._dropZone.addEventListener('dragleave', this._dragleave.bind(this));
      this._dropZone.addEventListener('drop', this._drop.bind(this));
    },

    uploadFiles: function(files) {
      if (!this.accepts(files)) {
        console.warn('Can only upload ' + this.accept +' files.');
        return;
      }
      if (!this.connection) {
        throw 'Missing connection';
      }
      if (!this.batchAppend || !this.uploader) {
        this.files = [];
        //this._newBatch().then(this._uploadeFiles.bind(this, files));
        this._newBatch();
        this._uploadeFiles(files);
      } else {
        this._uploadeFiles(files);
      }

    },

    batchExecute: function(operationId, params, headers) {
      return this.$.nx.operation(operationId).then(function(operation) {
        var options = {};
        if (headers) {
          options['headers'] = headers;
        }
        if (params.context) {
          operation = operation.context(params.context);
        }
        return operation.input(this.uploader)
          .params(params)
          .execute(options)
          .then(function(data) {
            this.fire('response', {response: data});
            this.response = data;
            return this.response;
          }.bind(this))
          .catch(function(error) {
            this.fire('error', error);
            console.log('Batch Execute operation failed: ' + error);
            throw error;
          }.bind(this));
      }.bind(this));
    },

    cancelBatch: function() {
      if (this.uploader) {
        if (this.uploader._batchId) {
          this.uploader.cancel();
        }
        this.uploader = null;
        this.batchId = null;
      }
    },

    _uploadeFiles: function(files) {
      var context = this;
      for (var i = 0; i < files.length; i++) {
        var file = files[i];
        file.idx = i;
        file.progress = 0;
        file.error = false;
        file.complete = false;
        this.push('files', file);
        //var blob = new Nuxeo.Blob({ content: file });
        this._uploadStarted(i, file);
        /*this.uploader.upload(blob)
          .then(function(result) {
            this._uploadFinished(result.blob.fileIdx);
          }.bind(this));*/
        this.getFileMd5(file).then(function(file){
          //this._computeMD5(file);
          //file.md5 = md5;
          this.s3.upload({
            Key: file.md5,
            Body: file,
            Metadata: {
              filename: file.name,
              mimeType: file.type
            }
          }, function(err, data) {
            if (err) {
              return alert('There was an error uploading your file: ', err.message);
            } else {
              context._uploadFinished(file.idx);
              context._batchFinished();
            }
          }).on('httpUploadProgress', function(evt) {
            var progress = parseInt((evt.loaded * 100) / evt.total);
            context._updateFile(file.idx, {
              progress: progress,
            });
          });
        }.bind(this));
      }
      /*this.uploader.done().then(function(result) {
        this._batchFinished(result.batch._batchId);
      }.bind(this));*/
    },

    _newBatch: function() {
      AWS.config.update({
        region: REGION,
        credentials: new AWS.CognitoIdentityCredentials({
          IdentityPoolId: CognitoID
        }),
        useAccelerateEndpoint: true
      });

      this.s3 = new AWS.S3({
        apiVersion: '2006-03-01',
        params: {
          region: REGION,
          Bucket: BUCKET
        }
      });
    },

    accepts: function(files) {
      if (files.length) {
        for (var i = 0; i < files.length; i++) {
          if (!this._accepts(files[i])) {
            return false;
          }
        }
        return true;
      } else {
        return this._accepts(files);
      }
    },

    _accepts: function(file) {
      var mimeType = ((file.type !== '') ? file.type.match(/^[^\/]*\//)[0] : null);
      var fileType = file.name.match(/\.[^\.]*$/)[0];
      if (this.accept && !(this.accept.indexOf(mimeType) > -1 || this.accept.indexOf(fileType) > -1)) {
        return false;
      } else {
        return true;
      }
    },

    _updateFile: function(index, values) {
      Object.keys(values).forEach(function (k) {
        this.set(['files', index, k].join('.'), values[k]);
      }.bind(this));
    },

    _batchFinished: function(batchId) {
      this.uploading = false;
      this.batchId = batchId;
      this.fire('batchFinished', {batchId: batchId});
    },

    _uploadStarted: function(fileIndex, file) {
      this.uploading = true;
    },

    _uploadFinished: function(index) {
      this._updateFile(index, {
        progress: 100,
        complete: true,
        index: index
      });
    },

    _uploadProgressUpdated: function(index, file, progress) {
      this._updateFile(index, {progress: progress}); // in percentage
    },

    _uploadSpeedUpdated: function(index, file, speed) {
      this._updateFile(index, {speed: speed}); // in KB/sec
    },

    // DnD
    _dragover: function(e) {
      e.preventDefault();
      this.toggleClass('hover', true, this._dropZone);
    },

    _dragleave: function() {
      this.toggleClass('hover', false, this._dropZone);
    },

    _drop: function(e) {
      this.toggleClass('hover', false, this._dropZone);
      e.preventDefault();
      this.uploadFiles(e.dataTransfer.files);
    },

    getFileMd5:function(file) {
      var promise = new Promise(function(resolve, reject) {
        var blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice,
            chunkSize = 2097152,                             // Read in chunks of 2MB
            chunks = Math.ceil(file.size / chunkSize),
            currentChunk = 0,
            spark = new SparkMD5.ArrayBuffer(),
            fileReader = new FileReader();

        fileReader.onload = function (e) {
            //dfd.notify('read chunk # ' + (currentChunk + 1) + ' of ' + chunks);
            spark.append(e.target.result);                   // Append array buffer
            currentChunk++;

            if (currentChunk < chunks) {
                loadNext();
            } else {
                file.md5 = spark.end();
                resolve(file);
            }
        };

        fileReader.onerror = function () {
            reject('oops, something went wrong.');
        };

        var loadNext = function() {
            var start = currentChunk * chunkSize,
                end = ((start + chunkSize) >= file.size) ? file.size : start + chunkSize;
            fileReader.readAsArrayBuffer(blobSlice.call(file, start, end));
        };

        loadNext();
      });
      return promise;
    }


  };
</script>
