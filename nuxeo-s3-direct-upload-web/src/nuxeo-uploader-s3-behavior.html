<!--
@license
(C) Copyright Nuxeo Corp. (http://nuxeo.com/)

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<script type="text/javascript" src="../bower_components/aws-sdk-js/dist/aws-sdk.js"></script>
<script type="text/javascript" src="../bower_components/js-spark-md5/spark-md5.js"></script>
<script type="text/javascript" src="../bower_components/es6-promise-pool/es6-promise-pool.js"></script>
<script type="text/javascript" src="../node_modules/crypto-js/crypto-js.js"></script>

<script>
  var Nuxeo = Nuxeo || {};

  const KEY = "vlad-work";

  const STORAGE_UPLOAD = 'nx_upload';

  const BUCKET = "l2it-bucket";
  const TOKEN_COGNITO = "us-east-1:2114898a-71dd-43c4-9bb6-1ea85db7baa4";

  /**
   * @polymerBehavior Nuxeo.UploaderBehavior
   */
  Nuxeo.S3UploaderBehavior = {

    properties: {
      /**
       * Accepted file extensions or mime types (comma separated values).
       */
      accept: String,

      /**
       * This flag determines whether the file should be immediately uploaded or not.
       */
      immediate: {
        type: Boolean,
        value: true
      },

      /**
       * Current batch id.
       */
      batchId: String,

      request: String,

      params: {
        type: Object,
        value: {}
      },

      fileChunks: {
        type: Array,
        value: []
      },

      /**
       * List of files in the current batch.
       */
      files: {
        type: Array,
        value: []
      },

      /**
       * Flag that indicates if an upload is in progress.
       */
      uploading: {
        type: Boolean,
        value: false
      },

      /**
       * Allow multiple files to be added to the same batch.
       */
      batchAppend: {
        type: Boolean,
        value: false
      },

      pause: {
        type: Boolean,
        value: false
      },

      batchReady:{
        type: Boolean,
        value: false
      },

      start:{
        type: Date
      }

    },

    setupDropZone: function (el) {
      this._dropZone = el;
      this._dropZone.addEventListener('dragover', this._dragover.bind(this));
      this._dropZone.addEventListener('dragleave', this._dragleave.bind(this));
      this._dropZone.addEventListener('drop', this._drop.bind(this));
    },

    uploadFiles: function (files) {
      if (!this.accepts(files)) {
        console.warn('Can only upload ' + this.accept + ' files.');
        return;
      }
      if (!this.connection) {
        throw 'Missing connection';
      }
      if (!this.batchAppend || !this.uploader) {
        this.files = [];
        poolWorker.postMessage(files);
        return;
      }
      this._uploadeFiles(files);
    },

    batchExecute: function (operationId, params, headers) {
      return this.$.nx.operation(operationId).then(function (operation) {
        var options = {};
        if (headers) {
          options['headers'] = headers;
        }
        if (params.context) {
          operation = operation.context(params.context);
        }
        return operation.input(this.uploader)
          .params(params)
          .execute(options)
          .then(function (data) {
            this.fire('response', {response: data});
            this.response = data;
            return this.response;
          }.bind(this))
          .catch(function (error) {
            this.fire('error', error);
            console.log('Batch Execute operation failed: ' + error);
            throw error;
          }.bind(this));
      }.bind(this));
    },

    cancelBatch: function () {
      if (this.uploader) {
        if (this.uploader._batchId) {
          this.uploader.cancel();
        }
        this.uploader = null;
        this.batchId = null;
      }
    },

    _store: function (file, context) {
      let upload = {
        'uploadId': context.request.response.data.UploadId,
        'md5': file.md5
      };
      localStorage.setItem(STORAGE_UPLOAD, JSON.stringify(upload));
    },

    _storageCleanup: function () {
      localStorage.removeItem(STORAGE_UPLOAD);
    },

    _getLastUpload: function () {
      let upload = JSON.parse(localStorage.getItem(STORAGE_UPLOAD));
      this._storageCleanup();
      return upload;
    },

    _getChunks: function (file) {
      let chunkSize = 1024 * 1024 * 5;
      let chunks = Math.ceil(file.size / chunkSize);
      let chunk = 0;
      let fileChunks = [];
      while (chunk < chunks) {
        let offset = chunk * chunkSize;
        fileChunks.push(file.slice(offset, offset + chunkSize));
        chunk++;
      }
      return fileChunks;
    },

    _uploadeFiles: function (files) {
      const context = this;
      const times = {};

      Array.prototype.forEach.call(files, function (file, i) {
        file.idx = i;
        file.progress = 0;
        file.error = false;
        file.complete = false;
        context.push('files', file);
        //var blob = new Nuxeo.Blob({ content: file });
        context._uploadStarted(i, file);
        /*this.uploader.upload(blob)
          .then(function(result) {
            this._uploadFinished(result.blob.fileIdx);
          }.bind(this));*/
        let progress;
        let lastProgress;
        context.getFileMd5(file).then(function (file) {

          // Store md5 and upload id
          context._store(file, context);

          const opts = {
            queueSize: 4
          };
          times[file.idx] = new Date().getTime();
          console.log(`Start: ${file.idx}: ${times[file.idx]}`);

          let fileChunks = context._getChunks(file);
          let chunkId = 1;

          context.start = new Date().getTime();

          context._multipartUpload(fileChunks, context, chunkId);
        }.bind(this));
      });
      /*this.uploader.done().then(function(result) {
        this._batchFinished(result.batch._batchId);
      }.bind(this));*/
    },

    _chunky(chunk, context, chunkId) {
      return new Promise(function (resolve, reject) {
        if (!context.pause) {
          context.getFileMd5(chunk).then(function (chunk) {
            //let md5hex = SparkMD5.hash(chunk.md5);
            var hash = CryptoJS.MD5(chunk.md5);
            let md5hex = hash.toString(CryptoJS.enc.Base64);
            let params0 = {
              Body: chunk,
              ContentMD5: md5hex,
              Bucket: BUCKET,
              Key: KEY,
              PartNumber: chunkId,
              UploadId: context.request.response.data.UploadId
            };
            context.s3.uploadPart(params0, function (err, data) {
              if (err) {
                console.log(err, err.stack);
                reject(err);
              } else {
                console.log(data + " uploaded");
                resolve();
              }
            });
          });
        } else {
          return null;
        }
      });
    },

    _multipartUpload(fileChunks, context, chunkId) {
      context.pause = false;
      context.fileChunks = fileChunks;
      let uploadsIterator = function* () {
        for (let count = chunkId - 1; count < fileChunks.length; count++) {
          yield context._chunky(fileChunks[count], context, chunkId);
          chunkId++;
        }
      };
      let pool = new PromisePool(uploadsIterator, 4);
      pool.start().then(function () {
        context._completeUpload(context);
      });
    },

    _completeUpload(context) {
      let params = {
        Bucket: BUCKET,
        Key: KEY,
        UploadId: this.request.response.data.UploadId
      };
      this.s3.listParts(params, function (err, data) {
        if (err) {
          console.log(err, err.stack);
        } else {
          this.params = {
            Bucket: BUCKET,
            Key: KEY,
            MultipartUpload: {
              Parts: this._formatParts(data.Parts)
            },
            UploadId: this.request.response.data.UploadId
          };
          this.s3.completeMultipartUpload(this.params, function (err, data) {
            if (err) {
              console.log(err, err.stack);
            }
            else {
              let timeDiff = new Date().getTime() - context.start;
              let seconds = timeDiff / 1000;
              console.log("Time elapsed: " + seconds + " seconds");
              console.log(data);
              this._storageCleanup();
            }
          }.bind(this));
        }
      }.bind(this));
    },

    pauseBlob () {
      this.pause = true;
    },

    abortBlob () {
      this.params = {
        Bucket: BUCKET,
        Key: KEY,
        UploadId: this.request.response.data.UploadId
      };
      this.s3.abortMultipartUpload(this.params, function (err, data) {
        if (err) console.log(err, err.stack);
        else console.log(data);
      });
    },

    resumeBlob(uploadId) {
      if (uploadId.type === null || typeof(uploadId.type) === 'undefined') {
        this.request.response.data.UploadId = uploadId;
      }
      let params = {
        Bucket: BUCKET,
        Key: KEY,
        UploadId: this.request.response.data.UploadId
      };
      this.s3.listParts(params, function (err, data) {
        if (err) {
          console.log(err, err.stack);
        } else {
          let uploadedChunks = this._formatParts(data.Parts);
          this.pause = false;
          this._multipartUpload(this.fileChunks, this, uploadedChunks.length + 1);
        }
      }.bind(this));
    },

    _formatParts: function (parts) {
      let formatParts = [];
      parts.map(function (part) {
        delete part.LastModified;
        delete part.Size;
        formatParts.push(part);
      });
      return formatParts;
    },

    accepts: function (files) {
      if (files.length) {
        for (var i = 0; i < files.length; i++) {
          if (!this._accepts(files[i])) {
            return false;
          }
        }
        return true;
      } else {
        return this._accepts(files);
      }
    },

    _accepts: function (file) {
      var mimeType = ((file.type !== '') ? file.type.match(/^[^\/]*\//)[0] : null);
      var fileType = file.name.match(/\.[^\.]*$/)[0];
      if (this.accept && !(this.accept.indexOf(mimeType) > -1 || this.accept.indexOf(fileType) > -1)) {
        return false;
      } else {
        return true;
      }
    },

    _updateFile: function (index, values) {
      Object.keys(values).forEach(function (k) {
        this.set(['files', index, k].join('.'), values[k]);
      }.bind(this));
    },

    _batchFinished: function (batchId) {
      this.uploading = false;
      this.batchId = batchId;
      this.fire('batchFinished', {batchId: batchId});
    },

    _uploadStarted: function (fileIndex, file) {
      this.uploading = true;
    },

    _uploadFinished: function (index) {
      this._updateFile(index, {
        progress: 100,
        complete: true,
        index: index
      });
    },

    _uploadProgressUpdated: function (index, file, progress) {
      this._updateFile(index, {progress: progress}); // in percentage
    },

    _uploadSpeedUpdated: function (index, file, speed) {
      this._updateFile(index, {speed: speed}); // in KB/sec
    },

    // DnD
    _dragover: function (e) {
      e.preventDefault();
      this.toggleClass('hover', true, this._dropZone);
    },

    _dragleave: function () {
      this.toggleClass('hover', false, this._dropZone);
    },

    _drop: function (e) {
      this.toggleClass('hover', false, this._dropZone);
      e.preventDefault();
      this.uploadFiles(e.dataTransfer.files);
    },

    getFileMd5: function (file) {
      var promise = new Promise(function (resolve, reject) {
        var chunkSize = 2097152,                             // Read in chunks of 2MB
          chunks = Math.ceil(file.size / chunkSize),
          currentChunk = 0,
          spark = new SparkMD5.ArrayBuffer(),
          fileReader = new FileReader();

        fileReader.onload = function (e) {
          //dfd.notify('read chunk # ' + (currentChunk + 1) + ' of ' + chunks);
          spark.append(e.target.result);                   // Append array buffer
          currentChunk++;

          if (currentChunk < chunks) {
            loadNext();
          } else {
            file.md5 = spark.end();
            resolve(file);
          }
        };

        fileReader.onerror = function () {
          reject('oops, something went wrong.');
        };

        var loadNext = function () {
          var start = currentChunk * chunkSize,
            end = ((start + chunkSize) >= file.size) ? file.size : start + chunkSize;
          fileReader.readAsArrayBuffer(file.slice(start, end));
        };

        loadNext();
      });
      return promise;
    }


  };
</script>
